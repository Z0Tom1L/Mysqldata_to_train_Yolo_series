from torch.utils.data import Dataset, DataLoader
import pymysql
import numpy as np
import torch
from PIL import Image
import io

class YOLOSQLDataset(Dataset):
    def __init__(self, db_config, img_size=640, subset='train'):
        self.img_size = img_size
        self.subset = subset
        self.conn = pymysql.connect(**db_config)
        self.cursor = self.conn.cursor()
        self.data = self.load_data()
        self._labels = self.load_labels()

    def load_data(self):
        sql = "SELECT id, img_data, annotation FROM images WHERE subset = %s"
        self.cursor.execute(sql, (self.subset,))
        return self.cursor.fetchall()

    def load_labels(self):
        labels = []
        for row in self.data:
            id, img_blob, annotation = row
            bboxes = []
            cls_list = []  # ğŸ‘ˆ æ–°å¢
            if annotation:
                lines = annotation.strip().split('\n')
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id, x, y, w, h = map(float, parts)
                        bboxes.append([class_id, x, y, w, h])
                        cls_list.append(class_id)  # ğŸ‘ˆ æ·»åŠ  class_id åˆ° cls_list
            labels.append({
                'bboxes': np.array(bboxes, dtype=np.float32),
                'cls': np.array(cls_list, dtype=np.float32)  # ğŸ‘ˆ æ–°å¢ cls å­—æ®µ
            })
        return labels

    @property
    def labels(self):
        return self._labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        id, img_blob, annotation = self.data[index]
        image = Image.open(io.BytesIO(img_blob)).convert("RGB")
        orig_w, orig_h = image.size
        ori_shape = (orig_h, orig_w)

        # resizeï¼ˆç¡®ä¿ padding æ—¶ä¿æŒæ¯”ä¾‹ä¸€è‡´ï¼‰
        image = image.resize((self.img_size, self.img_size))
        image = np.array(image).transpose(2, 0, 1)  # HWC -> CHW
        image = torch.from_numpy(image).float() / 255.0

        label = self._labels[index]
        bboxes = label['bboxes']
        if isinstance(bboxes, list):
            bboxes = np.array(bboxes, dtype=np.float32)

        if bboxes.ndim == 1:  # â›” é¿å… [cls, x, y, w, h] è¿™ç§å˜æˆ 1D çš„æƒ…å†µ
            bboxes = np.expand_dims(bboxes, axis=0)

        if bboxes.shape[0] == 0:
            target = torch.zeros((0, 5), dtype=torch.float32)
        else:
            target = torch.tensor(bboxes, dtype=torch.float32)
        # if len(label['bboxes']) == 0:
        #     target = torch.zeros((0, 5), dtype=torch.float32)
        # else:
        #     target = torch.tensor(label['bboxes'], dtype=torch.float32)  # shape [N, 5]

        # ratio_pad å¯ä»¥é¢„è®¾ä¸º ((1.0,), (0, 0))ï¼Œå¦‚æœä½ æ²¡æœ‰åš letterbox
        ratio_pad = ((1.0,), (0, 0))

        return image, target, ori_shape, ratio_pad

    @staticmethod
    def collate_fn(batch):
        imgs, targets, ori_shapes, ratio_pads = list(zip(*batch))

        # [B, 3, H, W]
        imgs = torch.stack(imgs, dim=0)

        batch_idx_list = []
        cls_list = []
        bboxes_list = []
        im_files = []

        for i, boxes in enumerate(targets):
            if boxes.numel() == 0:
                continue

            if boxes.ndim == 1:  # åªåŒ…å«ä¸€ä¸ªç›®æ ‡æ—¶ï¼Œå‡ç»´
                boxes = boxes.unsqueeze(0)

            batch_idx = torch.full((boxes.shape[0],), i, dtype=torch.int64)
            batch_idx_list.append(batch_idx)
            cls_list.append(boxes[:, 0].long())
            bboxes_list.append(boxes[:, 1:5].float())
            im_files.append(f"db_image_{i}.jpg")

        if batch_idx_list:
            batch_idx = torch.cat(batch_idx_list, dim=0)
            cls = torch.cat(cls_list, dim=0)
            bboxes = torch.cat(bboxes_list, dim=0)
        else:
            batch_idx = torch.empty((0,), dtype=torch.int64)
            cls = torch.empty((0,), dtype=torch.int64)
            bboxes = torch.empty((0, 4), dtype=torch.float32)

        # ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ é‡ç‚¹ï¼šç¡®ä¿ cls æ˜¯è‡³å°‘ 1D çš„ tensor
        if cls.ndim == 0:
            cls = cls.unsqueeze(0)

        return {
            "img": imgs,
            "batch_idx": batch_idx,
            "cls": cls,
            "bboxes": bboxes,
            "im_file": list(im_files),
            "ori_shape": list(ori_shapes),
            "ratio_pad": list(ratio_pads),
        }


def custom_collate_fn(batch):
    imgs, targets, ori_shapes, ratio_pads = list(zip(*batch))

    # [B, 3, H, W]
    imgs = torch.stack(imgs, dim=0)

    batch_idx_list = []
    cls_list = []
    bboxes_list = []
    im_files = []

    for i, boxes in enumerate(targets):
        if boxes.numel() == 0:
            continue

        # ğŸ”§ ä¿®å¤ï¼šé¿å… 1D tensor å¯¼è‡´åç»­é”™è¯¯
        if boxes.ndim == 1:
            boxes = boxes.unsqueeze(0)

        # i è¡¨ç¤º batch ä¸­çš„ç¬¬å‡ å¼ å›¾ç‰‡ï¼Œboxes.shape[0] æ˜¯è¯¥å›¾ä¸­çš„ç›®æ ‡æ•°
        batch_idx = torch.full((boxes.shape[0],), i, dtype=torch.int64)
        batch_idx_list.append(batch_idx)

        cls = boxes[:, 0].long()
        if cls.ndim == 0:
            cls = cls.unsqueeze(0)
        cls_list.append(cls)

        bboxes = boxes[:, 1:5].float()
        if bboxes.ndim == 1:
            bboxes = bboxes.unsqueeze(0)
        bboxes_list.append(bboxes)

        im_files.append(f"db_image_{i}.jpg")  # æ¨¡æ‹Ÿ filename

    # è‹¥ batch ä¸­æ²¡æœ‰ç›®æ ‡ï¼Œä¹Ÿä¸èƒ½å´©
    if batch_idx_list:
        batch_idx = torch.cat(batch_idx_list, dim=0)
        cls = torch.cat(cls_list, dim=0)
        bboxes = torch.cat(bboxes_list, dim=0)
    else:
        batch_idx = torch.empty((0,), dtype=torch.int64)
        cls = torch.empty((0,), dtype=torch.int64)
        bboxes = torch.empty((0, 4), dtype=torch.float32)

    if cls.ndim == 0:
        cls = cls.unsqueeze(0)
    return {
        "img": imgs,  # [B, 3, H, W]
        "batch_idx": batch_idx,  # [N]
        "cls": cls,  # [N]
        "bboxes": bboxes,  # [N, 4]
        "im_file": list(im_files),  # [B] => ç”¨äº plot_training_samples
        "ori_shape": list(ori_shapes),  # [B] => (h, w)
        "ratio_pad": list(ratio_pads),  # [B] => ((gain,), (pad_w, pad_h))
    }
class Dataloader:
    def __init__(self, db_config, batch_size=16, img_size=640):
        self.dataset = YOLOSQLDataset(db_config, img_size)
        self.dataloader = DataLoader(
            self.dataset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=0,  # å»ºè®®ä»0å¼€å§‹ï¼Œç¡®è®¤æ— çº¿ç¨‹é—®é¢˜åå¯è°ƒé«˜
            collate_fn=custom_collate_fn
        )

    def get_loader(self):
        return self.dataloader
